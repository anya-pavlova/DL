{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music classification and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys \n",
    "import wave\n",
    "import time\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from StringIO import StringIO\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/jtdc7y0bi00ii4p/genres.tar.gz?dl=0 -O genres.tar.gz \n",
    "!tar -xzf genres.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sound_file = './genres/blues/blues.00000.au'\n",
    "x, sample_rate = librosa.load(sound_file)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound as 1D-Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "pylab.plot(1.0* np.arange(len(x)) / sample_rate, x, 'k')\n",
    "pylab.xlim([0, 10])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound as 2D-Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(x, sr=sample_rate, n_mels=128)\n",
    "log_S = librosa.logamplitude(S, ref_power=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel', cmap='hot')\n",
    "plt.title('mel power spectrogram')\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(fname):\n",
    "    y, sr = librosa.load(fname)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sample_rate, n_mels=128)\n",
    "    log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "    return log_S[:, :1200]\n",
    "\n",
    "def plot_spectrogramm(log_S):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel', cmap='hot')\n",
    "    plt.title('mel power spectrogram')\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres = ['blues', 'country', 'hiphop', 'metal', 'reggae', 'classical', 'disco', 'jazz', 'pop', 'rock']\n",
    "\n",
    "id2genre = dict()\n",
    "X_names, y = [], []\n",
    "for genre_id, genre in enumerate(genres):\n",
    "    id2genre[genre_id] = genre\n",
    "    for track in os.listdir('./genres/' + genre):\n",
    "        if '.mp3' in track or '.au' in track and '_' not in track:\n",
    "            trackfile = os.path.join('./genres/', genre, track)\n",
    "            X_names.append(trackfile)\n",
    "            y.append(genre_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "#compute all spectrograms\n",
    "n_cpu = 5\n",
    "X = Pool(n_cpu).map(get_spectrogram, X_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors genre classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(y))\n",
    "X, X_names, y = np.array(X)[idx].astype('float32'), np.array(X_names)[idx], np.array(y)[idx]\n",
    "X_reshaped = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "n_train = 800\n",
    "X_train, X_valid = X_reshaped[:n_train], X_reshaped[n_train:]\n",
    "y_train, y_valid = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_jobs=n_cpu)\n",
    "\n",
    "clf = #train clf\n",
    "y_val_pred = #make prediction on validation set>\n",
    "\n",
    "print accuracy_score(y_valid, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://benanne.github.io/images/spotify_convnet.png)\n",
    "\n",
    "http://benanne.github.io/2014/08/05/spotify-cnns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_X, target_y = T.tensor3(\"X\", dtype='float32'), T.vector(\"y\", dtype='int32')\n",
    "nn = lasagne.layers.InputLayer(shape=(None, X.shape[1], X.shape[2]), input_var=input_X)\n",
    "\n",
    "nn = #Build your convnet using Conv1DLayer, MaxPool1DLayer, GlobalPoolLayer, or others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = lasagne.layers.get_output(nn)\n",
    "params = lasagne.layers.get_all_params(nn, trainable=True)\n",
    "\n",
    "loss = #define loss function\n",
    "accuracy = #define accuracy\n",
    "updates = #here goes your favorite optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_X, target_y], [loss, accuracy], allow_input_downcast=True, updates=updates)\n",
    "test_fn  = theano.function([input_X, target_y], [loss, accuracy], allow_input_downcast=True)\n",
    "predict_fn  = theano.function([input_X], y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "conv_nn = train_net(nn, train_fn, test_fn, X_train, y_train, X_valid, y_valid, num_epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Simular Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/cnn_gr.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_layer = #choose layer to for feature extraction (please don't pick the last layer!)\n",
    "features = lasagne.layers.get_output(features_layer, deterministic=True)\n",
    "features_fn = theano.function([input_X], features, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: np.array(features_fn([x]))\n",
    "track_vectors = map(f, X_train) + map(f, X_valid)\n",
    "track_vectors = np.concatenate(track_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_pred = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "nn_pred = nn_pred.fit(track_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = list(X_names[nn_pred.kneighbors(track_vectors[0])[1][0]])\n",
    "print ans\n",
    "#most of the nearest tracks should be from the same genre\n",
    "#if the feature extraction works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nearest tracks should be similar\n",
    "sound_file = ans[0]\n",
    "x, sample_rate = librosa.load(sound_file)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sound_file = ans[1]\n",
    "x, sample_rate = librosa.load(sound_file)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sound_file = ans[2]\n",
    "x, sample_rate = librosa.load(sound_file)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help: https://lts2.epfl.ch/blog/perekres/category/visualizing-hidden-structures-in-datasets-using-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = lambda x: np.array(features_fn([x]))\n",
    "track_vectors = map(f, X_train) + map(f, X_valid)\n",
    "track_vectors = np.concatenate(track_vectors, axis=0)\n",
    "\n",
    "track_labels = np.array(list(y_train) + list(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tsne = #apply tSNE\n",
    "#sklearn t-SNE manual also recommends to reduce dimensions of your data with PCA before applying t-SNE\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "colors = cm.plasma(np.linspace(0, 1.0, len(id2genre)))\n",
    "\n",
    "for idx, gener in id2genre.items():\n",
    "    idx_ = np.where(track_labels == idx)\n",
    "    plt.scatter(X_tsne[:, 0][idx_], X_tsne[:, 1][idx_], c=colors[idx], label=gener)\n",
    "\n",
    "plt.legend(loc=0, ncol=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "\n",
    "Maximum grade for this notebook is 9 points\n",
    "\n",
    "* train neural network for music style classification. Your grade will depend on validation set accuracy\n",
    "    * 40% - 2 points\n",
    "    * 60% - 4 points\n",
    "    * 80% - 6 points\n",
    "* music retrieval works correctly - 3 points\n",
    "\n",
    "Correct music retrieval means:\n",
    "* Same genre for most of the nearest neighbors. Using predicted probabilities as a feature to satisfy this rule is cheating!\n",
    "* Reasonable level of perceptual similarity of nearest neightbours\n",
    "* t-SNE plot looks likes tsne_example.png or better (tight clusters and fine structure is betters, random scatter is worse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
